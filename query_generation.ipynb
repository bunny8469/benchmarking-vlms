{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Generation from `query_templates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define specific attribute vocabularies\n",
    "known_colors = {\n",
    "    \"red\", \"blue\", \"green\", \"white\", \"black\", \"yellow\", \"brown\",\n",
    "    \"orange\", \"pink\", \"purple\", \"gray\"\n",
    "}\n",
    "\n",
    "known_shapes = {\n",
    "    \"round\", \"square\", \"triangular\", \"circular\", \"rectangular\"\n",
    "}\n",
    "\n",
    "known_materials = {\n",
    "    \"wooden\", \"metal\", \"plastic\", \"glass\", \"leather\", \"fabric\"\n",
    "}\n",
    "\n",
    "known_conditions = {\n",
    "    \"broken\", \"dirty\", \"clean\", \"wet\", \"dry\", \"old\", \"new\"\n",
    "}\n",
    "\n",
    "wearable_parts = {\n",
    "    \"shirt\", \"t-shirt\", \"jacket\", \"hat\", \"pants\", \"shoes\", \"scarf\",\n",
    "    \"dress\", \"jeans\", \"sneakers\", \"boots\"\n",
    "}\n",
    "\n",
    "def get_position_descriptor(obj, objects):\n",
    "    obj_type = obj['names'][0]\n",
    "    same_type = [o for o in objects if o['names'][0] == obj_type]\n",
    "    if len(same_type) <= 1:\n",
    "        return \"\"\n",
    "    x_center = obj['x'] + obj['w'] / 2\n",
    "    sorted_centers = sorted([o['x'] + o['w'] / 2 for o in same_type])\n",
    "    rank = sorted_centers.index(x_center)\n",
    "    if rank == 0:\n",
    "        return \" on the left\"\n",
    "    elif rank == len(sorted_centers) - 1:\n",
    "        return \" on the right\"\n",
    "    else:\n",
    "        return \" in the center\"\n",
    "\n",
    "def classify_attribute(attr):\n",
    "    attr = attr.lower()\n",
    "    if attr in known_colors:\n",
    "        return \"color\"\n",
    "    if attr in known_shapes:\n",
    "        return \"shape\"\n",
    "    if attr in known_materials:\n",
    "        return \"material\"\n",
    "    if attr in known_conditions:\n",
    "        return \"condition\"\n",
    "    return None\n",
    "\n",
    "def attribute_query(obj_name, attr, attr_type, position_desc):\n",
    "    if attr_type == \"color\":\n",
    "        return f\"What color is the {obj_name}{position_desc}?\"\n",
    "    elif attr_type == \"shape\":\n",
    "        return f\"What is the shape of the {obj_name}{position_desc}?\"\n",
    "    elif attr_type == \"material\":\n",
    "        return f\"What material is the {obj_name}{position_desc} made of?\"\n",
    "    elif attr_type == \"condition\":\n",
    "        return f\"What is the condition of the {obj_name}{position_desc}?\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/scratch/anony_ai/cache/sentence_transformers\"\n",
    "\n",
    "import json\n",
    "import time\n",
    "import ijson\n",
    "import random\n",
    "from typing import List, Dict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from models.mistral import get_correlated_objects, get_alternate_relationships\n",
    "from tqdm import tqdm\n",
    "\n",
    "class QueryGenerator:\n",
    "    def __init__(self, templates_path=\"query_templates.json\"):\n",
    "        \n",
    "        with open(templates_path) as f:\n",
    "            self.templates = json.load(f)\n",
    "\n",
    "        self.levels = {\n",
    "            1: self.generate_level_1_queries,\n",
    "            2: self.generate_level_2_queries,\n",
    "            3: self.generate_level_3_queries,\n",
    "            4: self.generate_level_4_queries,\n",
    "            5: self.generate_level_5_queries,\n",
    "        }\n",
    "\n",
    "        print(\"Loading TF!\")\n",
    "        self.tf_model = SentenceTransformer('all-MiniLM-L6-v2', cache_folder='/scratch/anony_ai/cache/sentence_transformers')\n",
    "        print(\"TF loaded!\")\n",
    "\n",
    "    def generate_level_1_queries(self, scene_graphs: List[Dict], num_objects: int = 5) -> List[Dict]:\n",
    "        \n",
    "        queries = []\n",
    "        level_templates = self.templates[\"level_1\"][\"templates\"]\n",
    "        \n",
    "        for sg in tqdm(scene_graphs):\n",
    "            # Get unique objects (avoid duplicates like multiple \"bike\" entries)\n",
    "            unique_objects = list({obj[\"name\"].lower() for obj in sg[\"objects\"]})\n",
    "            sampled_objects = random.sample(unique_objects, min(num_objects, len(unique_objects)))\n",
    "            \n",
    "            for obj in sampled_objects:\n",
    "                template = random.choice(level_templates)\n",
    "                query = template.replace(\"<object>\", obj)\n",
    "                \n",
    "                queries.append({\n",
    "                    \"image_id\": sg.get(\"url\", \"\"),\n",
    "                    \"question\": query,\n",
    "                    \"answer\": \"Yes\",  # Always \"Yes\" since objects come from scene graph\n",
    "                    \"instruction\": self.templates[\"level_1\"][\"instruction\"],\n",
    "                    \"level\": 1\n",
    "                })\n",
    "        \n",
    "        return queries\n",
    "    \n",
    "    def generate_level_2_queries(self, scene_graphs: List[Dict], num_objects: int = 5) -> List[Dict]:\n",
    "        queries = []\n",
    "        level_templates = self.templates[\"level_2\"][\"templates\"]\n",
    "        \n",
    "        for sg in tqdm(scene_graphs):\n",
    "            # Get unique objects (avoid duplicates like multiple \"bike\" entries)\n",
    "            unique_objects = list({obj[\"name\"].lower() for obj in sg[\"objects\"]})\n",
    "            unique_objects = random.sample(unique_objects, min(num_objects, len(unique_objects)))\n",
    "            \n",
    "            sampled_objects = []\n",
    "            \n",
    "            for obj in unique_objects:\n",
    "                correlated_objs = get_correlated_objects(obj, k=3)\n",
    "                sampled_objects.extend(correlated_objs)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            sampled_objects_dummy=sampled_objects\n",
    "            sampled_objects=[]\n",
    "            \n",
    "            similar_flag = False\n",
    "            for corr_obj in sampled_objects_dummy:\n",
    "                for obj in unique_objects:\n",
    "                    embeddings = self.tf_model.encode([obj, corr_obj])\n",
    "                    if cosine_similarity([embeddings[0]], [embeddings[1]])[0][0] > 0.7:\n",
    "                        similar_flag = True\n",
    "                        continue\n",
    "                \n",
    "                if not similar_flag:\n",
    "                    sampled_objects.append(corr_obj)\n",
    "                else:\n",
    "                    similar_flag = False\n",
    "\n",
    "            sampled_objects = list(set(sampled_objects))\n",
    "            sampled_objects = random.sample(sampled_objects, min(num_objects, len(sampled_objects)))\n",
    "            \n",
    "            for obj in sampled_objects:\n",
    "                template = random.choice(level_templates)\n",
    "                query = template.replace(\"<object>\", obj)\n",
    "                \n",
    "                queries.append({\n",
    "                    \"image_id\": sg.get(\"url\", \"\"),\n",
    "                    \"question\": query,\n",
    "                    \"answer\": \"No\",  # Also check if the object is present in the image or not\n",
    "                    \"instruction\": self.templates[\"level_1\"][\"instruction\"],\n",
    "                    \"level\": 2\n",
    "                })\n",
    "        \n",
    "        return queries\n",
    "\n",
    "    def generate_level_3_queries(self, scene_graphs: List[Dict], num_objects: int = 5) -> List[Dict]:\n",
    "        level_templates = self.templates[\"level_3\"][\"templates\"]\n",
    "\n",
    "        queries = []\n",
    "        seen = set()\n",
    "\n",
    "        for entry in tqdm(scene_graphs):\n",
    "            image_id = entry.get(\"url\")\n",
    "        \n",
    "            # Create mapping from object index to name\n",
    "            obj_index_to_name = {i: obj[\"name\"] for i, obj in enumerate(entry.get(\"objects\", []))}\n",
    "            \n",
    "            for rel in entry.get(\"relationships\", []):\n",
    "                predicate = rel.get(\"predicate\")\n",
    "                subject_idx = rel.get(\"subject\")\n",
    "                object_idx = rel.get(\"object\")\n",
    "                \n",
    "                # Get names using the indices\n",
    "                subject = obj_index_to_name.get(subject_idx)\n",
    "                obj = obj_index_to_name.get(object_idx)\n",
    "                \n",
    "                key = (image_id, subject, obj, predicate)\n",
    "                if key in seen or subject == obj or not subject or not obj:\n",
    "                    continue\n",
    "                \n",
    "                seen.add(key)\n",
    "\n",
    "                template = random.choice(level_templates)\n",
    "                query = template.replace(\"<object>\", obj)\n",
    "                query = query.replace(\"<subject>\", subject)\n",
    "\n",
    "                queries.append({\n",
    "                    \"image_id\": image_id,\n",
    "                    \"question\": query,\n",
    "                    \"answer\": predicate,\n",
    "                    \"subject\": subject,\n",
    "                    \"object\": obj,\n",
    "                    \"level\": 3\n",
    "                })\n",
    "\n",
    "        return queries\n",
    "\n",
    "    def generate_level_4_queries(self, scene_graphs: List[Dict], num_relations: int = 5) -> List[Dict]:\n",
    "        level_templates = self.templates[\"level_4\"][\"templates\"]\n",
    "        queries = []\n",
    "        seen = set()\n",
    "\n",
    "        for entry in tqdm(scene_graphs):\n",
    "            image_id = entry.get(\"url\")\n",
    "            obj_index_to_name = {i: obj[\"name\"] for i, obj in enumerate(entry.get(\"objects\", []))}\n",
    "            relationships = entry.get(\"relationships\", [])\n",
    "\n",
    "            # Extract unique relationships for the current scene graph\n",
    "            unique_relationships = set(rel.get(\"predicate\") for rel in relationships if rel.get(\"predicate\"))\n",
    "            formatted_relationships = ', '.join(f\"'{rel}'\" for rel in unique_relationships)\n",
    "\n",
    "            sampled_relations = random.sample(relationships, min(num_relations, len(relationships)))\n",
    "            \n",
    "            for rel in sampled_relations:\n",
    "                predicate = rel.get(\"predicate\")\n",
    "                subject_idx = rel.get(\"subject\")\n",
    "                object_idx = rel.get(\"object\")\n",
    "\n",
    "                subject = obj_index_to_name.get(subject_idx)\n",
    "                obj = obj_index_to_name.get(object_idx)\n",
    "                \n",
    "                key = (image_id, subject, obj, predicate)\n",
    "                \n",
    "                if key in seen or subject == obj or not subject or not obj:\n",
    "                    continue\n",
    "                \n",
    "                seen.add(key)\n",
    "\n",
    "                # Pass unique relationships specific to the current scene graph\n",
    "                alternate_relationships = get_alternate_relationships(\n",
    "                    relationship=rel, object_name=obj, existing_relationships=formatted_relationships, subject_name=subject, k=3\n",
    "                )\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                if len(alternate_relationships) == 0:\n",
    "                    continue\n",
    "                \n",
    "                template = random.choice(level_templates)\n",
    "                query = template.replace(\"<object>\", obj)\n",
    "                query = query.replace(\"<subject>\", subject)\n",
    "\n",
    "                queries.append({\n",
    "                    \"image_id\": image_id,\n",
    "                    \"question\": query,\n",
    "                    \"answer\": predicate,\n",
    "                    \"options\": alternate_relationships,\n",
    "                    \"subject\": subject,\n",
    "                    \"object\": obj,\n",
    "                    \"level\": 4\n",
    "                })\n",
    "        \n",
    "        return queries\n",
    "\n",
    "    def generate_level_5_queries(self, scene_graphs, num_attributes=5):\n",
    "        \n",
    "        queries_by_type = defaultdict(list)\n",
    "        print(\"Level 5\")\n",
    "        \n",
    "        for graph in tqdm(scene_graphs):\n",
    "            \n",
    "            objects = graph['objects']\n",
    "            objects = random.sample(objects, min(10, len(objects)))\n",
    "            for obj in objects:\n",
    "                if 'names' not in obj or not obj['names']:\n",
    "                    continue\n",
    "\n",
    "                obj_name = obj['names'][0].lower()\n",
    "                attributes = obj.get('attributes', [])\n",
    "                if not attributes:\n",
    "                    continue\n",
    "\n",
    "                attributes = random.sample(attributes, min(3, len(attributes)))\n",
    "\n",
    "                position_desc = get_position_descriptor(obj, objects)\n",
    "\n",
    "                for attr in attributes:\n",
    "                    attr_type = classify_attribute(attr)\n",
    "                    if not attr_type:\n",
    "                        continue\n",
    "\n",
    "                    query = attribute_query(obj_name, attr, attr_type, position_desc)\n",
    "                    if query:\n",
    "                        queries_by_type[attr_type].append({\n",
    "                            \"image_id\": graph['image_id'],\n",
    "                            \"object\": obj_name,\n",
    "                            \"attribute\": attr,\n",
    "                            \"query\": query,\n",
    "                            \"answer\": attr\n",
    "                        })\n",
    "                        \n",
    "        return queries_by_type\n",
    "\n",
    "    def generate_queries(self, scene_graphs_path: str, output_path: str, level: int = 1):\n",
    "       \n",
    "        with open(scene_graphs_path) as f:\n",
    "            scene_graphs = json.load(f)\n",
    "        \n",
    "        if level == 5:\n",
    "            image_ids = [item[\"url\"] for item in scene_graphs]\n",
    "            filtered_scene_graphs = []\n",
    "            with open(\"./VisualGenome/scene_graphs.json\") as f:\n",
    "                parser = ijson.items(f, \"item\")\n",
    "                for graph in parser:\n",
    "                    if graph[\"image_id\"] in image_ids:\n",
    "                        filtered_scene_graphs.append(graph)\n",
    "\n",
    "            queries = self.levels[level](filtered_scene_graphs)\n",
    "            \n",
    "        else:              \n",
    "                \n",
    "            queries = self.levels[level](scene_graphs)\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(queries, f, indent=2)\n",
    "        \n",
    "        print(f\"Generated {len(queries)} Level {level} queries at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF!\n",
      "TF loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:00<00:00, 50175.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1055 Level 1 queries at ./queries/queries_level_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qg = QueryGenerator()\n",
    "qg.generate_queries(\n",
    "    scene_graphs_path=\"./assets/final_subset_19.json\",\n",
    "    output_path=\"./queries/queries_level_1.json\",\n",
    "    level=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF!\n",
      "TF loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [17:24<00:00,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1051 Level 2 queries at ./queries/queries_level_2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qg = QueryGenerator()\n",
    "qg.generate_queries(\n",
    "    scene_graphs_path=\"./assets/final_subset_19.json\",\n",
    "    output_path=\"./queries/queries_level_2.json\",\n",
    "    level=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF!\n",
      "TF loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:00<00:00, 27662.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 935 Level 3 queries at ./queries/queries_level_3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qg = QueryGenerator()\n",
    "qg.generate_queries(\n",
    "    scene_graphs_path=\"./assets/final_subset_19.json\",\n",
    "    output_path=\"./queries/queries_level_3.json\",\n",
    "    level=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF!\n",
      "TF loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [10:09<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 352 Level 4 queries at ./queries/queries_level_4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "qg = QueryGenerator()\n",
    "qg.generate_queries(\n",
    "    scene_graphs_path=\"./assets/final_subset_19.json\",\n",
    "    output_path=\"./queries/queries_level_4.json\",\n",
    "    level=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF!\n",
      "TF loaded!\n",
      "Level 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:00<00:00, 30459.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 Level 5 queries at ./queries/queries_attr.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "qg = QueryGenerator()\n",
    "qg.generate_queries(\n",
    "    scene_graphs_path=\"./assets/final_subset_19.json\",\n",
    "    output_path=\"./queries/queries_attr.json\",\n",
    "    level=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrinsic Object Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 93 Level 4 queries at ./queries/queries_level_4.json\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define specific attribute vocabularies\n",
    "known_colors = {\n",
    "    \"red\", \"blue\", \"green\", \"white\", \"black\", \"yellow\", \"brown\",\n",
    "    \"orange\", \"pink\", \"purple\", \"gray\"\n",
    "}\n",
    "\n",
    "known_shapes = {\n",
    "    \"round\", \"square\", \"triangular\", \"circular\", \"rectangular\"\n",
    "}\n",
    "\n",
    "known_materials = {\n",
    "    \"wooden\", \"metal\", \"plastic\", \"glass\", \"leather\", \"fabric\"\n",
    "}\n",
    "\n",
    "known_conditions = {\n",
    "    \"broken\", \"dirty\", \"clean\", \"wet\", \"dry\", \"old\", \"new\"\n",
    "}\n",
    "\n",
    "wearable_parts = {\n",
    "    \"shirt\", \"t-shirt\", \"jacket\", \"hat\", \"pants\", \"shoes\", \"scarf\",\n",
    "    \"dress\", \"jeans\", \"sneakers\", \"boots\"\n",
    "}\n",
    "\n",
    "def get_position_descriptor(obj, objects):\n",
    "    obj_type = obj['names'][0]\n",
    "    same_type = [o for o in objects if o['names'][0] == obj_type]\n",
    "    if len(same_type) <= 1:\n",
    "        return \"\"\n",
    "    x_center = obj['x'] + obj['w'] / 2\n",
    "    sorted_centers = sorted([o['x'] + o['w'] / 2 for o in same_type])\n",
    "    rank = sorted_centers.index(x_center)\n",
    "    if rank == 0:\n",
    "        return \" on the left\"\n",
    "    elif rank == len(sorted_centers) - 1:\n",
    "        return \" on the right\"\n",
    "    else:\n",
    "        return \" in the center\"\n",
    "\n",
    "def classify_attribute(attr):\n",
    "    attr = attr.lower()\n",
    "    if attr in known_colors:\n",
    "        return \"color\"\n",
    "    if attr in known_shapes:\n",
    "        return \"shape\"\n",
    "    if attr in known_materials:\n",
    "        return \"material\"\n",
    "    if attr in known_conditions:\n",
    "        return \"condition\"\n",
    "    return None\n",
    "\n",
    "def attribute_query(obj_name, attr, attr_type, position_desc):\n",
    "    if attr_type == \"color\":\n",
    "        return f\"What color is the {obj_name}{position_desc}?\"\n",
    "    elif attr_type == \"shape\":\n",
    "        return f\"What is the shape of the {obj_name}{position_desc}?\"\n",
    "    elif attr_type == \"material\":\n",
    "        return f\"What material is the {obj_name}{position_desc} made of?\"\n",
    "    elif attr_type == \"condition\":\n",
    "        return f\"What is the condition of the {obj_name}{position_desc}?\"\n",
    "    return None\n",
    "\n",
    "def generate_attribute_hallucination_queries(scene_graphs_path, image_ids, output_path):\n",
    "    with open(scene_graphs_path, 'r') as f:\n",
    "        scene_graphs = json.load(f)\n",
    "\n",
    "    queries_by_type = defaultdict(list)\n",
    "\n",
    "    for graph in scene_graphs:\n",
    "        if graph['image_id'] not in image_ids:\n",
    "            continue\n",
    "\n",
    "        objects = graph['objects']\n",
    "        for obj in objects:\n",
    "            if 'names' not in obj or not obj['names']:\n",
    "                continue\n",
    "\n",
    "            obj_name = obj['names'][0].lower()\n",
    "            attributes = obj.get('attributes', [])\n",
    "            if not attributes:\n",
    "                continue\n",
    "\n",
    "            position_desc = get_position_descriptor(obj, objects)\n",
    "\n",
    "            for attr in attributes:\n",
    "                attr_type = classify_attribute(attr)\n",
    "                if not attr_type:\n",
    "                    continue\n",
    "\n",
    "                query = attribute_query(obj_name, attr, attr_type, position_desc)\n",
    "                if query:\n",
    "                    queries_by_type[attr_type].append({\n",
    "                        \"image_id\": graph['image_id'],\n",
    "                        \"object\": obj_name,\n",
    "                        \"attribute\": attr,\n",
    "                        \"query\": query,\n",
    "                        \"answer\": attr\n",
    "                    })\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(queries_by_type, f, indent=2)\n",
    "    print(f\"Saved {sum(len(v) for v in queries_by_type.values())} queries with answers to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "image_ids = [1, 3, 7, 8, 10, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "scene_graphs_path = \"./VisualGenome/scene_graphs.json\"\n",
    "output_path = \"attribute_hallucination_queries_with_answers.json\"\n",
    "\n",
    "generate_attribute_hallucination_queries(scene_graphs_path, image_ids, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "363dfc2adefd0fe23b82d9a6244049edf1ce33df26e212f804a52758e7d5303e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
